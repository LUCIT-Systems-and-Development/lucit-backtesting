{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Heatmap\n",
    "==========\n",
    "\n",
    "This tutorial will show how to optimize strategies with multiple parameters and how to examine and reason about optimization results.\n",
    "It is assumed you're already familiar with\n",
    "[basic _backtesting.py_ usage](https://kernc.github.io/backtesting.py/doc/examples/Quick%20Start%20User%20Guide.html).\n",
    "\n",
    "First, let's again import our helper moving average function.\n",
    "In practice, one should use functions from an indicator library, such as\n",
    "[TA-Lib](https://github.com/mrjbq7/ta-lib) or\n",
    "[Tulipy](https://tulipindicators.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": "from lucit_backtesting.test import SMA",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our strategy will be a similar moving average cross-over strategy to the one in\n",
    "[Quick Start User Guide](https://kernc.github.io/backtesting.py/doc/examples/Quick%20Start%20User%20Guide.html),\n",
    "but we will use four moving averages in total:\n",
    "two moving averages whose relationship determines a general trend\n",
    "(we only trade long when the shorter MA is above the longer one, and vice versa),\n",
    "and two moving averages whose cross-over with daily _close_ prices determine the signal to enter or exit the position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "from lucit_backtesting import Strategy\n",
    "from lucit_backtesting.lib import crossover\n",
    "\n",
    "\n",
    "class Sma4Cross(Strategy):\n",
    "    n1 = 50\n",
    "    n2 = 100\n",
    "    n_enter = 20\n",
    "    n_exit = 10\n",
    "    \n",
    "    def init(self):\n",
    "        self.sma1 = self.I(SMA, self.data.Close, self.n1)\n",
    "        self.sma2 = self.I(SMA, self.data.Close, self.n2)\n",
    "        self.sma_enter = self.I(SMA, self.data.Close, self.n_enter)\n",
    "        self.sma_exit = self.I(SMA, self.data.Close, self.n_exit)\n",
    "        \n",
    "    def next(self):\n",
    "        \n",
    "        if not self.position:\n",
    "            \n",
    "            # On upwards trend, if price closes above\n",
    "            # \"entry\" MA, go long\n",
    "            \n",
    "            # Here, even though the operands are arrays, this\n",
    "            # works by implicitly comparing the two last values\n",
    "            if self.sma1 > self.sma2:\n",
    "                if crossover(self.data.Close, self.sma_enter):\n",
    "                    self.buy()\n",
    "                    \n",
    "            # On downwards trend, if price closes below\n",
    "            # \"entry\" MA, go short\n",
    "            \n",
    "            else:\n",
    "                if crossover(self.sma_enter, self.data.Close):\n",
    "                    self.sell()\n",
    "        \n",
    "        # But if we already hold a position and the price\n",
    "        # closes back below (above) \"exit\" MA, close the position\n",
    "        \n",
    "        else:\n",
    "            if (self.position.is_long and\n",
    "                crossover(self.sma_exit, self.data.Close)\n",
    "                or\n",
    "                self.position.is_short and\n",
    "                crossover(self.data.Close, self.sma_exit)):\n",
    "                \n",
    "                self.position.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not a robust strategy, but we can optimize it.\n",
    "\n",
    "[Grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search)\n",
    "is an exhaustive search through a set of specified sets of values of hyperparameters. One evaluates the performance for each set of parameters and finally selects the combination that performs best.\n",
    "\n",
    "Let's optimize our strategy on Google stock data using _randomized_ grid search over the parameter space, evaluating at most (approximately) 200 randomly chosen combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "from lucit_backtesting import Backtest\n",
    "from lucit_backtesting.test import GOOG\n",
    "\n",
    "\n",
    "backtest = Backtest(GOOG, Sma4Cross, commission=.002)\n",
    "\n",
    "stats, heatmap = backtest.optimize(\n",
    "    n1=range(10, 110, 10),\n",
    "    n2=range(20, 210, 20),\n",
    "    n_enter=range(15, 35, 5),\n",
    "    n_exit=range(10, 25, 5),\n",
    "    constraint=lambda p: p.n_exit < p.n_enter < p.n1 < p.n2,\n",
    "    maximize='Equity Final [$]',\n",
    "    max_tries=200,\n",
    "    random_state=0,\n",
    "    return_heatmap=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `return_heatmap=True` parameter passed to\n",
    "[`Backtest.optimize()`](https://kernc.github.io/backtesting.py/doc/backtesting/backtesting.html#backtesting.backtesting.Backtest.optimize).\n",
    "It makes the function return a heatmap series along with the usual stats of the best run.\n",
    "`heatmap` is a pandas Series indexed with a MultiIndex, a cartesian product of all permissible (tried) parameter values.\n",
    "The series values are from the `maximize=` argument we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "heatmap"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap contains the results of all the runs,\n",
    "making it very easy to obtain parameter combinations for e.g. three best runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "heatmap.sort_values().iloc[-3:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we use vision to make judgements on larger data sets much faster.\n",
    "Let's plot the whole heatmap by projecting it on two chosen dimensions.\n",
    "Say we're mostly interested in how parameters `n1` and `n2`, on average, affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "hm = heatmap.groupby(['n1', 'n2']).mean().unstack()\n",
    "hm"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this table using the excellent [_Seaborn_](https://seaborn.pydata.org) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.heatmap(hm[::-1], cmap='viridis')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, on average, we obtain the highest result using trend-determining parameters `n1=40` and `n2=60`,\n",
    "and it's not like other nearby combinations work similarly well â€” in our particular strategy, this combination really stands out.\n",
    "\n",
    "Since our strategy contains several parameters, we might be interested in other relationships between their values.\n",
    "We can use\n",
    "[`backtesting.lib.plot_heatmaps()`](https://kernc.github.io/backtesting.py/doc/backtesting/lib.html#backtesting.lib.plot_heatmaps)\n",
    "function to plot interactive heatmaps of all parameter combinations simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "from lucit_backtesting.lib import plot_heatmaps\n",
    "\n",
    "\n",
    "plot_heatmaps(heatmap, agg='mean')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based optimization\n",
    "\n",
    "Above, we used _randomized grid search_ optimization method. Any kind of grid search, however, might be computationally expensive for large data sets. In the follwing example, we will use\n",
    "[_scikit-optimize_](https://scikit-optimize.github.io)\n",
    "package to guide our optimization better informed using forests of decision trees.\n",
    "The hyperparameter model is sequentially improved by evaluating the expensive function (the backtest) at the next best point, thereby hopefully converging to a set of optimal parameters with as few evaluations as possible.\n",
    "\n",
    "So, with `method=\"skopt\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "%%capture\n",
    "\n",
    "! pip install scikit-optimize  # This is a run-time dependency"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "stats_skopt, heatmap, optimize_result = backtest.optimize(\n",
    "    n1=[10, 100],      # Note: For method=\"skopt\", we\n",
    "    n2=[20, 200],      # only need interval end-points\n",
    "    n_enter=[10, 40],\n",
    "    n_exit=[10, 30],\n",
    "    constraint=lambda p: p.n_exit < p.n_enter < p.n1 < p.n2,\n",
    "    maximize='Equity Final [$]',\n",
    "    method='skopt',\n",
    "    max_tries=200,\n",
    "    random_state=0,\n",
    "    return_heatmap=True,\n",
    "    return_optimization=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "heatmap.sort_values().iloc[-3:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the optimization runs somewhat slower even though `max_tries=` is the same. But that's due to the sequential nature of the algorithm and should actually perform rather comparably even in cases of _much larger parameter spaces_ where grid search would effectively blow up, but likely (hopefully) reaching a better local optimum than a randomized search would.\n",
    "A note of warning, again, to take steps to avoid\n",
    "[overfitting](https://en.wikipedia.org/wiki/Overfitting)\n",
    "insofar as possible.\n",
    "\n",
    "Understanding the impact of each parameter on the computed objective function is easy in two dimensions, but as the number of dimensions grows, partial dependency plots are increasingly useful.\n",
    "[Plotting tools from _scikit-optimize_](https://scikit-optimize.github.io/stable/modules/plots.html)\n",
    "take care of many of the more mundane things needed to make good and informative plots of the parameter space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from skopt.plots import plot_objective\n",
    "\n",
    "_ = plot_objective(optimize_result, n_points=10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "from skopt.plots import plot_evaluations\n",
    "\n",
    "_ = plot_evaluations(optimize_result, bins=10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more by exploring further\n",
    "[examples](https://kernc.github.io/backtesting.py/doc/backtesting/index.html#tutorials)\n",
    "or find more framework options in the\n",
    "[full API reference](https://kernc.github.io/backtesting.py/doc/backtesting/index.html#header-submodules)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
